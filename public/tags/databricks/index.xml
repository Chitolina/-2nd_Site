<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DataBricks on </title>
    <link>/tags/databricks/</link>
    <description>Recent content in DataBricks on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 06 Dec 2021 19:36:52 -0300</lastBuildDate><atom:link href="/tags/databricks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Big Data - PySpark &amp; SQL</title>
      <link>/2021/12/big-data-pyspark-sql/</link>
      <pubDate>Mon, 06 Dec 2021 19:36:52 -0300</pubDate>
      
      <guid>/2021/12/big-data-pyspark-sql/</guid>
      <description>Big Data for Data Scientists - From Mega to Giga In this post we are going to learn about the use of some tools to apply on Big Data, that differs a bit from a normal pandas-csv methodology. Working with Big Data usually demands more sophisticated software that can deal with the upload and storage of Gyga files. This was a great module I had from &amp;ldquo;Stack Academy - Big Data for Data Scientist&amp;rdquo; that, for its massive importance and content, I decided to bring to my portfolio.</description>
    </item>
    
  </channel>
</rss>
